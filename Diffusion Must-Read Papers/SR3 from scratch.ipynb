{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944d6511",
   "metadata": {},
   "source": [
    "# Image Super-Resolution via Iterative Refinement\n",
    "\n",
    "#### With additional functions upon the original codes\n",
    "\n",
    "*Code Writer: Chaeeun Ryu*\n",
    "\n",
    "references: \n",
    "- https://nn.labml.ai/diffusion/ddpm/unet.html\n",
    "- https://github.com/KiUngSong/Generative-Models/tree/main\n",
    "- https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement/\n",
    "- https://arxiv.org/abs/2102.09672\n",
    "- https://arxiv.org/pdf/2104.14951.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c3e5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math, os, copy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd56c5a",
   "metadata": {},
   "source": [
    "# Define U-net Architecture:\n",
    "\n",
    "Approximate reverse diffusion process by using U-net<br>\n",
    "U-net of SR3 : U-net backbone + Positional Encoding of time + Multihead Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed4e8c",
   "metadata": {},
   "source": [
    "**Swish activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "761fc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return x*torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f051e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncoding Source： https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype,\n",
    "                            device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(\n",
    "            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat(\n",
    "            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ddd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(\n",
    "                batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7152f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c968428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(\n",
    "            noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31d5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\n",
    "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
    "        ).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30af8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlockWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33500446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlockWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True),\n",
    "            ResnetBlockWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlockWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlockWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlockWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlockWithAttn):\n",
    "                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffac2cb",
   "metadata": {},
   "source": [
    "register_buffer: 연산하는데 GPU를 사용하지만, backpropagation을 통해 update는 안 되는 값을 저장할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf70836",
   "metadata": {},
   "source": [
    "# Diffusion Process Framework\n",
    "\n",
    "#### TL;DR: Predict noise! \n",
    "\n",
    "**Contributions**\n",
    "- Huber loss added as loss type\n",
    "- lengthened linear schedule added for schedule types\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "##### Diffusion Computations\n",
    "\n",
    "Computing $x_t$ directly in **forward process**, given $x_0$<br><br>\n",
    "$$x_t = \\sqrt{\\bar{\\alpha}_{t}}x_0 + \\sqrt{1-\\bar{\\alpha}_{t} }\\epsilon$$\n",
    "$\\alpha_t := 1-\\beta_t$<br>\n",
    "$\\bar{\\alpha}_t := \\Pi^t_{s=0}\\alpha_s$<br>\n",
    "$q(x_t|x_0) = \\mathcal{N}(x_t;\\sqrt{\\bar{\\alpha}_t}x_0, (1-\\bar{\\alpha}_t)I)$<br>\n",
    "$x_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}}(x_t-\\sqrt{1-\\bar{\\alpha}_t}\\epsilon)$\n",
    "$=\\frac{1}{\\sqrt{\\bar{\\alpha}_t}}x_t - \\sqrt{\\frac{1}{\\bar{\\alpha}_t}-1}\\epsilon$\n",
    "\n",
    "<br><br>\n",
    "Computing mean and variance of posteriors for **reverse process**\n",
    "\n",
    "$$q(x_{t-1}|x_t,x_0) \\sim \\mathcal{N}(x_{t-1}; \\tilde{\\mu_t}(x_0,x_t),\\tilde{\\beta_t}(x_0,x_t)I)$$\n",
    "\n",
    "$\\tilde{\\mu_t}(x_0,x_t) = \\frac{\\beta_t(\\sqrt{\\bar{\\alpha}_{t-1}})}{1-\\bar{\\alpha}_t}x_0+\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\alpha_t}x_t$<br>\n",
    "$\\tilde{\\beta_t}(x_0,x_t) = \\beta_t(\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\alpha_t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e00bb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, model, device, img_size, LR_size, channels = 3):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.img_size = img_size\n",
    "        self.LR_size = LR_size\n",
    "    \n",
    "    #Set loss type\n",
    "    def set_loss(self, type_):\n",
    "        if type_ == 'l1':\n",
    "            print(f\"loss type: L1\")\n",
    "            self.loss_func = nn.L1Loss(reduction = 'sum')\n",
    "        elif type_ == 'l2':\n",
    "            print(f\"loss type: L2\")\n",
    "            self.loss_func = nn.MSELoss(reduction='sum')\n",
    "        else:\n",
    "            print(f\"loss type: Huber Loss\")\n",
    "            self.loss_func = nn.HuberLoss(reduction = 'sum')\n",
    "            \n",
    "    #Set scheduling for Beta as Cosine, and also modifications to Cosine\n",
    "    def make_beta_schedule(self, schedule_type, n_timestep):\n",
    "        if schedule_type == 'cosine':\n",
    "            cosine_s = 8e-3\n",
    "            timesteps = torch.arange(n_timestep+1,dtype = torch.float64)/n_timestep + cosine_s\n",
    "            alphas = timesteps/(1+cosine_s)*math.pi/2\n",
    "            alphas = alphas/alphas[0]\n",
    "            betas = 1 - alphas[1:]/alphas[:-1]\n",
    "            betas = betas.clamp(max = 0.999)\n",
    "            return betas\n",
    "        \n",
    "        elif schedule_type == 'lengthened_linear':\n",
    "            #original linear start: 0.0001\n",
    "            #original linear end: 0.02\n",
    "            linear_start = 0.00001\n",
    "            linear_end = 0.005\n",
    "            betas = np.linspace(linear_start, linear_end, n_timestep, dtype=np.float64)\n",
    "            return betas\n",
    "        else:\n",
    "            print(\"schedule tpe not assigned properly!\")\n",
    "            return\n",
    "    \n",
    "    def set_new_noise_schedule(self, schedule_option):\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32, device=self.device)#지정된 type으로 torch tensor 만드는 함수\n",
    "        betas = self.make_beta_schedule(\n",
    "            schedule=schedule_opt['schedule'],\n",
    "            n_timestep=schedule_opt['n_timestep'],\n",
    "            linear_start=schedule_opt['linear_start'],\n",
    "            linear_end=schedule_opt['linear_end'])\n",
    "        betas = betas.detach().cpu().numpy() if isinstance(betas, torch.Tensor) else betas\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])#마지막 t번째 alpha 제외한 나머지끼리의 곱\n",
    "        self.sqrt_alphas_cumprod_prev = np.sqrt(np.append(1., alphas_cumprod))\n",
    "        \n",
    "        self.num_timesteps = int(len(betas))\n",
    "        \n",
    "        # Coefficient for forward diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))#\\bar{alpha_t}\n",
    "        self.register_buffer('alphas_cumprod_prev', to_torch(alphas_cumprod_prev))#\\bar{alpha_t-1}\n",
    "        #forward process에서 x0을 예측할 때 x_t앞의 coefficient\n",
    "        self.register_buffer('pred_coef_xt', to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        #forward process에서 x0을 예측할 때 noise앞의 (-1)*coefficient\n",
    "        self.register_buffer('pred_coef_noise', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        ###Coefficient for reverse diffusion posterior q(x_{t-1} | x_t, x_0)\n",
    "        #reverse process에서 posterior variance 구할 때 Beta_t의 coefficient (=variance)\n",
    "        variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)#predicted variance for reverse process\n",
    "        self.register_buffer('variance', to_torch(variance))\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(np.log(np.maximum(variance, 1e-20))))\n",
    "        #reverse process에서 posterior mean 구할 때 x0앞 coefficient\n",
    "        self.register_buffer('posterior_mean_coef_x0', to_torch(betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        #reverse process에서 posterior mean 구할 때 xt앞 coefficient\n",
    "        self.register_buffer('posterior_mean_coef_xt', to_torch((1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "        \n",
    "    def predict_x0(self, x_t, t, noise):#x0을 위 공식대로 구함\n",
    "        return self.pred_coef_xt[t]*x_t - self.pred_coef_noise[t]*noise\n",
    "    \n",
    "    def q_posterior(self,x_start,x_t,t):\n",
    "        posterior_mu = self.posterior_mean_coef_x0[t]*x_start + self.posterior_mean_coef_xt[t]*x_t\n",
    "        posterior_log_var = self.posterior_log_variance_clipped[t]\n",
    "        return posterior_mu, posterior_log_var         \n",
    "    \n",
    "    #construct x0 and predict q's mean variance (=reverse process)\n",
    "    def q_mean_variance(self, x, t, clip_denoised:bool, condition_x = None):\n",
    "        batch_size = x.shape[0]\n",
    "        noise_level = torch.FloatTensor([self.sqrt_alphas_cumprod_prev[t+1]]).repeat(batch_size,1).to(x.device)\n",
    "        x_recon = self.predict_start(x,t,noise = self.model(torch.cat([condition_x,x],dim = 1),noise_level))#reconstruct x0\n",
    "        \n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1.,1.)\n",
    "        mean, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t = x, t=t)\n",
    "        return mean, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self,x,t,clip_denoised = True, condition_x = None):\n",
    "        mean, log_variance = self.q_mean_variance(x=x,t=t,clip_denoised=clip_denoised,condition_x=condition_x)\n",
    "        noise = torch.rand_like(x) if t>0 else torch.zeros_like(x)\n",
    "        return mean+noise*(0.5*log_variance).exp()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self,x_in):\n",
    "        img = torch.rand_like(x_in,device=x_in.device)\n",
    "        for i in reversed(range(0,self.num_timesteps)):\n",
    "            img = self.p_sample(img,i,condition_x=x_in)\n",
    "        return img\n",
    "    \n",
    "    def p_losses(self,x_in):\n",
    "        x_start = x_in\n",
    "        #lr_imgs: made low resolution images\n",
    "        lr_imgs = transforms.Resize(self.img_size)(transforms.Resize(self.LR_size)(x_in))\n",
    "        b,c,h,w = x_start.shape\n",
    "        t = np.random.randint(1,self.num_timesteps+1)\n",
    "        sqrt_alpha = torch.FloatTensor(np.random.uniform(self.sqrt_alphas_cumprod_prev[t-1], self.sqrt_alphas_cumprod_prev[t],size = b)).to(x_start.device)\n",
    "        sqrt_alpha = sqrt_alpha.view(-1,1,1,1)\n",
    "        noise = torch.rand_like(x_start).to(x_start.device)\n",
    "        #perturbed image\n",
    "        x_noisy = sqrt_alpha*x_start+(1-sqrt_alpha**2).sqrt()*noise\n",
    "        pred_noise = self.model(torch.cat([lr_imgs,x_noisy],dim = 1),noise_level=sqrt_alpha)\n",
    "        return self.loss_func(noise,pred_noise)\n",
    "    \n",
    "    def forward(self,x,*args,**kwargs):\n",
    "        return self.p_losses(x,*args,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07654035",
   "metadata": {},
   "source": [
    "# Image Super-Resolution via Iterative Refinement(SR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7fa6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "global args_dict\n",
    "args_dict = dict()\n",
    "args_dict['load_path'] = None\n",
    "args_dict['load'] = False\n",
    "args_dict['in_channel'] = 6\n",
    "args_dict['out_channel'] = 3\n",
    "args_dict['inner_channel'] = 32\n",
    "args_dict['norm_groups'] = 8\n",
    "args_dict['channel_mults'] = (1, 2, 4, 8, 8)\n",
    "args_dict['res_blocks'] = 3\n",
    "args_dict['dropout'] = 0\n",
    "args_dict['lr'] = 1e-5\n",
    "args_dict['distributed'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR3:\n",
    "    def __init__(self, args_dict):\n",
    "        self.dataloader = args_dict['dataloader']\n",
    "        self.testloader = args_dict['testloader']\n",
    "        self.device = args_dict['device']\n",
    "        self.save_path = args_dict['save_path']\n",
    "        self.img_size = args_dict['img_size']\n",
    "        self.LR_size = args_dict['LR_size']\n",
    "        \n",
    "        model = UNet(args_dict['in_channel'], args_dict['out_channel'], args_dict['inner_channel'], args_dict['norm_groups'], args_dict['channel_mults'], args_dict['res_blocks'], args_dict['dropout'], args_dict['img_size'])\n",
    "        self.sr3 = Diffusion(model, self.device, self.img_size, self.LR_size, args_dict['out_channel'])\n",
    "        \n",
    "        #Apply weight initialization & set loss & set noise schedule\n",
    "        self.sr3.apply(self.weights_init_orthogonal)\n",
    "        self.sr3.set_loss(loss_type)\n",
    "                \n",
    "    def train(self):\n",
    "        \n",
    "    def test(self,imgs):\n",
    "        imgs_lr = tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d01c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde24486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460b197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db92c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7a4655",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71268130",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7dfc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "LR_size = 32#low resolution size\n",
    "img_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91b453",
   "metadata": {},
   "source": [
    "### Train and Test Data\n",
    "\n",
    "- Train with: FFHQ\n",
    "- Inference on: CELEB A HQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de66f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
